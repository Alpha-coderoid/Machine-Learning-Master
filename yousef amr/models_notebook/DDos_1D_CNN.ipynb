{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-12T15:31:22.666469Z",
     "iopub.status.busy": "2026-01-12T15:31:22.665773Z",
     "iopub.status.idle": "2026-01-12T15:31:22.671774Z",
     "shell.execute_reply": "2026-01-12T15:31:22.671031Z",
     "shell.execute_reply.started": "2026-01-12T15:31:22.666442Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:51:39.336716Z",
     "iopub.status.busy": "2026-01-12T15:51:39.336115Z",
     "iopub.status.idle": "2026-01-12T15:51:39.342278Z",
     "shell.execute_reply": "2026-01-12T15:51:39.341553Z",
     "shell.execute_reply.started": "2026-01-12T15:51:39.336689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T13:11:23.872003Z",
     "iopub.status.busy": "2026-01-12T13:11:23.871160Z",
     "iopub.status.idle": "2026-01-12T13:11:23.876730Z",
     "shell.execute_reply": "2026-01-12T13:11:23.876171Z",
     "shell.execute_reply.started": "2026-01-12T13:11:23.871969Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "def compute_f1_scores(y_true, y_pred, model_name=\"Model\"):\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    f1_micro = f1_score(y_true, y_pred, average=\"micro\")\n",
    "\n",
    "    print(f\"\\n=== {model_name} F1 Scores ===\")\n",
    "    print(f\"Macro F1    : {f1_macro:.4f}\")\n",
    "    print(f\"Weighted F1 : {f1_weighted:.4f}\")\n",
    "    print(f\"Micro F1    : {f1_micro:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        \"f1_micro\": f1_micro\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:49:56.663913Z",
     "iopub.status.busy": "2026-01-12T15:49:56.663641Z",
     "iopub.status.idle": "2026-01-12T15:49:58.758444Z",
     "shell.execute_reply": "2026-01-12T15:49:58.757823Z",
     "shell.execute_reply.started": "2026-01-12T15:49:56.663893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df_test= pd.read_csv(\"/kaggle/input/k-fold-dataset/data_final_v/test.csv\")\n",
    "df_train = pd.read_csv(\"/kaggle/input/k-fold-dataset/data_final_v/train.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:50:00.308403Z",
     "iopub.status.busy": "2026-01-12T15:50:00.307941Z",
     "iopub.status.idle": "2026-01-12T15:50:00.360917Z",
     "shell.execute_reply": "2026-01-12T15:50:00.360044Z",
     "shell.execute_reply.started": "2026-01-12T15:50:00.308373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['label','label_encoded'\n",
    "])\n",
    "y_train = df_train['label_encoded']\n",
    "X_test = df_test.drop(columns=['label','label_encoded'\n",
    "])\n",
    "y_test = df_test['label_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:50:03.093295Z",
     "iopub.status.busy": "2026-01-12T15:50:03.093026Z",
     "iopub.status.idle": "2026-01-12T15:50:03.098220Z",
     "shell.execute_reply": "2026-01-12T15:50:03.097422Z",
     "shell.execute_reply.started": "2026-01-12T15:50:03.093274Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available: 2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"GPUs available:\", torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:50:10.113782Z",
     "iopub.status.busy": "2026-01-12T15:50:10.112955Z",
     "iopub.status.idle": "2026-01-12T15:50:10.122503Z",
     "shell.execute_reply": "2026-01-12T15:50:10.121800Z",
     "shell.execute_reply.started": "2026-01-12T15:50:10.113754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def Training(\n",
    "    model,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    epochs=100,\n",
    "    lr=1e-3,\n",
    "    patience=10,\n",
    "    batch_size=256\n",
    "):\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    num_classes = 12\n",
    "\n",
    "   \n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_val   = torch.tensor(X_val, dtype=torch.float32).unsqueeze(1)\n",
    "    y_val   = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train),\n",
    "                              batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(TensorDataset(X_val, y_val),\n",
    "                              batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(xb), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                val_loss += criterion(model(xb), yb).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train={train_loss:.4f}, Val={val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_weights)\n",
    "    return model, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:53:26.586343Z",
     "iopub.status.busy": "2026-01-12T15:53:26.585398Z",
     "iopub.status.idle": "2026-01-12T15:53:26.592618Z",
     "shell.execute_reply": "2026-01-12T15:53:26.592070Z",
     "shell.execute_reply.started": "2026-01-12T15:53:26.586308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_f1_per_class(model, X, y):\n",
    "    model.eval()\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_tensor).argmax(dim=1)\n",
    "\n",
    "    report = classification_report(\n",
    "        y_tensor.cpu().numpy(),\n",
    "        y_pred.cpu().numpy(),\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    f1_per_class = {f\"class_{i}\": report.get(str(i), {}).get(\"f1-score\", 0.0)\n",
    "                    for i in range(12)}\n",
    "    macro_f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "    return macro_f1, f1_per_class\n",
    "\n",
    "\n",
    "def evaluate_confusion_matrix(model, X, y):\n",
    "    model.eval()\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_tensor).argmax(dim=1)\n",
    "\n",
    "    return confusion_matrix(y, y_pred.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:50:14.638667Z",
     "iopub.status.busy": "2026-01-12T15:50:14.638001Z",
     "iopub.status.idle": "2026-01-12T15:50:14.645963Z",
     "shell.execute_reply": "2026-01-12T15:50:14.645119Z",
     "shell.execute_reply.started": "2026-01-12T15:50:14.638637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def kfold_training(\n",
    "    model_class,\n",
    "    model_kwargs,\n",
    "    X, y,\n",
    "    k=5,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    lr=1e-3,\n",
    "    patience=10\n",
    "):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    best_model, best_f1, best_fold = None, -1, -1\n",
    "    models, histories = [], []\n",
    "\n",
    "    X_np = X.values if hasattr(X, \"values\") else X\n",
    "    y_np = y.values if hasattr(y, \"values\") else y\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_np, y_np), 1):\n",
    "        print(f\"\\n========== Fold {fold}/{k} ==========\")\n",
    "\n",
    "        model = model_class(**model_kwargs).to(device)\n",
    "\n",
    "        model, train_loss, val_loss = Training(\n",
    "            model,\n",
    "            X_np[train_idx], y_np[train_idx],\n",
    "            X_np[val_idx], y_np[val_idx],\n",
    "            epochs, lr, patience, batch_size\n",
    "        )\n",
    "\n",
    "        macro_f1, per_class_f1 = evaluate_f1_per_class(\n",
    "            model, X_np[val_idx], y_np[val_idx]\n",
    "        )\n",
    "\n",
    "        cm = evaluate_confusion_matrix(\n",
    "            model, X_np[val_idx], y_np[val_idx]\n",
    "        )\n",
    "\n",
    "        print(f\"Fold {fold} | Macro F1: {macro_f1:.4f}\")\n",
    "\n",
    "        if macro_f1 > best_f1:\n",
    "            best_f1, best_model, best_fold = macro_f1, copy.deepcopy(model), fold\n",
    "\n",
    "        models.append(model)\n",
    "        histories.append({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"macro_f1\": macro_f1,\n",
    "            \"per_class_f1\": per_class_f1,\n",
    "            \"confusion_matrix\": cm\n",
    "        })\n",
    "\n",
    "    print(f\" Best Model ‚Üí Fold {best_fold} | Macro F1 = {best_f1:.4f}\")\n",
    "    return best_model, models, histories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:59:16.306556Z",
     "iopub.status.busy": "2026-01-12T15:59:16.306275Z",
     "iopub.status.idle": "2026-01-12T16:34:56.357059Z",
     "shell.execute_reply": "2026-01-12T16:34:56.356453Z",
     "shell.execute_reply.started": "2026-01-12T15:59:16.306534Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1/5 ==========\n",
      "Epoch 1: Train=0.5015, Val=0.2061\n",
      "Epoch 2: Train=0.2171, Val=0.1737\n",
      "Epoch 3: Train=0.1883, Val=0.1554\n",
      "Epoch 4: Train=0.1722, Val=0.1621\n",
      "Epoch 5: Train=0.1634, Val=0.1496\n",
      "Epoch 6: Train=0.1574, Val=0.1320\n",
      "Epoch 7: Train=0.1516, Val=0.1363\n",
      "Epoch 8: Train=0.1458, Val=0.1272\n",
      "Epoch 9: Train=0.1423, Val=0.1382\n",
      "Epoch 10: Train=0.1366, Val=0.1167\n",
      "Epoch 11: Train=0.1330, Val=0.1189\n",
      "Epoch 12: Train=0.1278, Val=0.1161\n",
      "Epoch 13: Train=0.1237, Val=0.1059\n",
      "Epoch 14: Train=0.1225, Val=0.1100\n",
      "Epoch 15: Train=0.1206, Val=0.1049\n",
      "Epoch 16: Train=0.1161, Val=0.1082\n",
      "Epoch 17: Train=0.1156, Val=0.1051\n",
      "Epoch 18: Train=0.1138, Val=0.1004\n",
      "Epoch 19: Train=0.1116, Val=0.0995\n",
      "Epoch 20: Train=0.1106, Val=0.0978\n",
      "Epoch 21: Train=0.1089, Val=0.0992\n",
      "Epoch 22: Train=0.1098, Val=0.0970\n",
      "Epoch 23: Train=0.1073, Val=0.0952\n",
      "Epoch 24: Train=0.1067, Val=0.0969\n",
      "Epoch 25: Train=0.1055, Val=0.0938\n",
      "Epoch 26: Train=0.1052, Val=0.0962\n",
      "Epoch 27: Train=0.1054, Val=0.0915\n",
      "Epoch 28: Train=0.1034, Val=0.0918\n",
      "Epoch 29: Train=0.1030, Val=0.0920\n",
      "Epoch 30: Train=0.1024, Val=0.0965\n",
      "Epoch 31: Train=0.1013, Val=0.0942\n",
      "Epoch 32: Train=0.1009, Val=0.0921\n",
      "Epoch 33: Train=0.1007, Val=0.0896\n",
      "Epoch 34: Train=0.1009, Val=0.0903\n",
      "Epoch 35: Train=0.0999, Val=0.0902\n",
      "Epoch 36: Train=0.0985, Val=0.0905\n",
      "Epoch 37: Train=0.0990, Val=0.0881\n",
      "Epoch 38: Train=0.0988, Val=0.0881\n",
      "Epoch 39: Train=0.0975, Val=0.0913\n",
      "Epoch 40: Train=0.0977, Val=0.0906\n",
      "Epoch 41: Train=0.0963, Val=0.0903\n",
      "Epoch 42: Train=0.0967, Val=0.0891\n",
      "Epoch 43: Train=0.0964, Val=0.0883\n",
      "Epoch 44: Train=0.0953, Val=0.0900\n",
      "Epoch 45: Train=0.0956, Val=0.0903\n",
      "Epoch 46: Train=0.0958, Val=0.0871\n",
      "Epoch 47: Train=0.0957, Val=0.0901\n",
      "Epoch 48: Train=0.0946, Val=0.0954\n",
      "Epoch 49: Train=0.0948, Val=0.0869\n",
      "Epoch 50: Train=0.0934, Val=0.0849\n",
      "Epoch 51: Train=0.0935, Val=0.0862\n",
      "Epoch 52: Train=0.0938, Val=0.0995\n",
      "Epoch 53: Train=0.0929, Val=0.0852\n",
      "Epoch 54: Train=0.0933, Val=0.0894\n",
      "Epoch 55: Train=0.0936, Val=0.0876\n",
      "Epoch 56: Train=0.0928, Val=0.0870\n",
      "Epoch 57: Train=0.0921, Val=0.0875\n",
      "Epoch 58: Train=0.0919, Val=0.0879\n",
      "Epoch 59: Train=0.0919, Val=0.0867\n",
      "Epoch 60: Train=0.0927, Val=0.0878\n",
      "‚èπ Early stopping\n",
      "Fold 1 | Macro F1: 0.7202\n",
      "\n",
      "========== Fold 2/5 ==========\n",
      "Epoch 1: Train=0.4783, Val=0.1988\n",
      "Epoch 2: Train=0.2035, Val=0.1595\n",
      "Epoch 3: Train=0.1776, Val=0.1421\n",
      "Epoch 4: Train=0.1633, Val=0.1335\n",
      "Epoch 5: Train=0.1499, Val=0.1264\n",
      "Epoch 6: Train=0.1440, Val=0.1250\n",
      "Epoch 7: Train=0.1337, Val=0.1180\n",
      "Epoch 8: Train=0.1310, Val=0.1108\n",
      "Epoch 9: Train=0.1280, Val=0.1113\n",
      "Epoch 10: Train=0.1262, Val=0.1044\n",
      "Epoch 11: Train=0.1219, Val=0.1137\n",
      "Epoch 12: Train=0.1210, Val=0.1072\n",
      "Epoch 13: Train=0.1186, Val=0.1036\n",
      "Epoch 14: Train=0.1168, Val=0.1036\n",
      "Epoch 15: Train=0.1148, Val=0.1044\n",
      "Epoch 16: Train=0.1128, Val=0.0986\n",
      "Epoch 17: Train=0.1125, Val=0.0977\n",
      "Epoch 18: Train=0.1104, Val=0.0973\n",
      "Epoch 19: Train=0.1082, Val=0.0974\n",
      "Epoch 20: Train=0.1078, Val=0.0942\n",
      "Epoch 21: Train=0.1085, Val=0.0982\n",
      "Epoch 22: Train=0.1066, Val=0.0948\n",
      "Epoch 23: Train=0.1078, Val=0.0971\n",
      "Epoch 24: Train=0.1051, Val=0.1001\n",
      "Epoch 25: Train=0.1035, Val=0.0925\n",
      "Epoch 26: Train=0.1029, Val=0.0992\n",
      "Epoch 27: Train=0.1025, Val=0.0938\n",
      "Epoch 28: Train=0.1024, Val=0.0909\n",
      "Epoch 29: Train=0.1014, Val=0.0924\n",
      "Epoch 30: Train=0.1004, Val=0.0961\n",
      "Epoch 31: Train=0.1001, Val=0.0907\n",
      "Epoch 32: Train=0.0997, Val=0.0930\n",
      "Epoch 33: Train=0.0990, Val=0.0912\n",
      "Epoch 34: Train=0.0985, Val=0.0890\n",
      "Epoch 35: Train=0.0998, Val=0.0954\n",
      "Epoch 36: Train=0.0991, Val=0.0893\n",
      "Epoch 37: Train=0.0977, Val=0.0898\n",
      "Epoch 38: Train=0.0964, Val=0.0881\n",
      "Epoch 39: Train=0.0961, Val=0.0897\n",
      "Epoch 40: Train=0.0962, Val=0.0885\n",
      "Epoch 41: Train=0.0961, Val=0.0892\n",
      "Epoch 42: Train=0.0945, Val=0.0887\n",
      "Epoch 43: Train=0.0954, Val=0.0868\n",
      "Epoch 44: Train=0.0955, Val=0.0873\n",
      "Epoch 45: Train=0.0950, Val=0.0896\n",
      "Epoch 46: Train=0.0944, Val=0.0883\n",
      "Epoch 47: Train=0.0947, Val=0.0860\n",
      "Epoch 48: Train=0.0942, Val=0.0884\n",
      "Epoch 49: Train=0.0944, Val=0.0869\n",
      "Epoch 50: Train=0.0931, Val=0.0853\n",
      "Epoch 51: Train=0.0938, Val=0.0889\n",
      "Epoch 52: Train=0.0931, Val=0.0877\n",
      "Epoch 53: Train=0.0926, Val=0.0877\n",
      "Epoch 54: Train=0.0926, Val=0.0879\n",
      "Epoch 55: Train=0.0930, Val=0.0890\n",
      "Epoch 56: Train=0.0924, Val=0.0867\n",
      "Epoch 57: Train=0.0922, Val=0.0894\n",
      "Epoch 58: Train=0.0916, Val=0.0874\n",
      "Epoch 59: Train=0.0920, Val=0.0881\n",
      "Epoch 60: Train=0.0917, Val=0.0884\n",
      "‚èπ Early stopping\n",
      "Fold 2 | Macro F1: 0.7458\n",
      "\n",
      "========== Fold 3/5 ==========\n",
      "Epoch 1: Train=0.4904, Val=0.1958\n",
      "Epoch 2: Train=0.2094, Val=0.1613\n",
      "Epoch 3: Train=0.1826, Val=0.1527\n",
      "Epoch 4: Train=0.1694, Val=0.1443\n",
      "Epoch 5: Train=0.1614, Val=0.1383\n",
      "Epoch 6: Train=0.1551, Val=0.1434\n",
      "Epoch 7: Train=0.1448, Val=0.1226\n",
      "Epoch 8: Train=0.1390, Val=0.1459\n",
      "Epoch 9: Train=0.1353, Val=0.1178\n",
      "Epoch 10: Train=0.1301, Val=0.1083\n",
      "Epoch 11: Train=0.1270, Val=0.1113\n",
      "Epoch 12: Train=0.1231, Val=0.1071\n",
      "Epoch 13: Train=0.1205, Val=0.1019\n",
      "Epoch 14: Train=0.1180, Val=0.1024\n",
      "Epoch 15: Train=0.1175, Val=0.1049\n",
      "Epoch 16: Train=0.1162, Val=0.1034\n",
      "Epoch 17: Train=0.1132, Val=0.1040\n",
      "Epoch 18: Train=0.1117, Val=0.0984\n",
      "Epoch 19: Train=0.1093, Val=0.1018\n",
      "Epoch 20: Train=0.1095, Val=0.0980\n",
      "Epoch 21: Train=0.1074, Val=0.0944\n",
      "Epoch 22: Train=0.1073, Val=0.0992\n",
      "Epoch 23: Train=0.1054, Val=0.0940\n",
      "Epoch 24: Train=0.1073, Val=0.1057\n",
      "Epoch 25: Train=0.1057, Val=0.0927\n",
      "Epoch 26: Train=0.1049, Val=0.0921\n",
      "Epoch 27: Train=0.1038, Val=0.0932\n",
      "Epoch 28: Train=0.1032, Val=0.0933\n",
      "Epoch 29: Train=0.1027, Val=0.0964\n",
      "Epoch 30: Train=0.1011, Val=0.0939\n",
      "Epoch 31: Train=0.1006, Val=0.0911\n",
      "Epoch 32: Train=0.1004, Val=0.0940\n",
      "Epoch 33: Train=0.1009, Val=0.0890\n",
      "Epoch 34: Train=0.0994, Val=0.0895\n",
      "Epoch 35: Train=0.0996, Val=0.0880\n",
      "Epoch 36: Train=0.0991, Val=0.0909\n",
      "Epoch 37: Train=0.0977, Val=0.0905\n",
      "Epoch 38: Train=0.0979, Val=0.0929\n",
      "Epoch 39: Train=0.0977, Val=0.0869\n",
      "Epoch 40: Train=0.0965, Val=0.0879\n",
      "Epoch 41: Train=0.0990, Val=0.0900\n",
      "Epoch 42: Train=0.0978, Val=0.0926\n",
      "Epoch 43: Train=0.0993, Val=0.0881\n",
      "Epoch 44: Train=0.0956, Val=0.0885\n",
      "Epoch 45: Train=0.0954, Val=0.0890\n",
      "Epoch 46: Train=0.0949, Val=0.0895\n",
      "Epoch 47: Train=0.0963, Val=0.0886\n",
      "Epoch 48: Train=0.0944, Val=0.0863\n",
      "Epoch 49: Train=0.0951, Val=0.0877\n",
      "Epoch 50: Train=0.0946, Val=0.0887\n",
      "Epoch 51: Train=0.0936, Val=0.0854\n",
      "Epoch 52: Train=0.0943, Val=0.0858\n",
      "Epoch 53: Train=0.0932, Val=0.0874\n",
      "Epoch 54: Train=0.0936, Val=0.0868\n",
      "Epoch 55: Train=0.0931, Val=0.0865\n",
      "Epoch 56: Train=0.0923, Val=0.0852\n",
      "Epoch 57: Train=0.0929, Val=0.0856\n",
      "Epoch 58: Train=0.0917, Val=0.0865\n",
      "Epoch 59: Train=0.0921, Val=0.0849\n",
      "Epoch 60: Train=0.0915, Val=0.0851\n",
      "Epoch 61: Train=0.0911, Val=0.0843\n",
      "Epoch 62: Train=0.0913, Val=0.0847\n",
      "Epoch 63: Train=0.0919, Val=0.0870\n",
      "Epoch 64: Train=0.0913, Val=0.0864\n",
      "Epoch 65: Train=0.0912, Val=0.0837\n",
      "Epoch 66: Train=0.0907, Val=0.0856\n",
      "Epoch 67: Train=0.0906, Val=0.0849\n",
      "Epoch 68: Train=0.0908, Val=0.0835\n",
      "Epoch 69: Train=0.0901, Val=0.0832\n",
      "Epoch 70: Train=0.0902, Val=0.0834\n",
      "Epoch 71: Train=0.0892, Val=0.0842\n",
      "Epoch 72: Train=0.0899, Val=0.0830\n",
      "Epoch 73: Train=0.0898, Val=0.0837\n",
      "Epoch 74: Train=0.0894, Val=0.0836\n",
      "Epoch 75: Train=0.0892, Val=0.0843\n",
      "Epoch 76: Train=0.0899, Val=0.0830\n",
      "Epoch 77: Train=0.0890, Val=0.0825\n",
      "Epoch 78: Train=0.0896, Val=0.0848\n",
      "Epoch 79: Train=0.0883, Val=0.0831\n",
      "Epoch 80: Train=0.0880, Val=0.0824\n",
      "Epoch 81: Train=0.0883, Val=0.0827\n",
      "Epoch 82: Train=0.0890, Val=0.0848\n",
      "Epoch 83: Train=0.0887, Val=0.0821\n",
      "Epoch 84: Train=0.0876, Val=0.0827\n",
      "Epoch 85: Train=0.0880, Val=0.0829\n",
      "Epoch 86: Train=0.0878, Val=0.0848\n",
      "Epoch 87: Train=0.0872, Val=0.0827\n",
      "Epoch 88: Train=0.0873, Val=0.0832\n",
      "Epoch 89: Train=0.0874, Val=0.0824\n",
      "Epoch 90: Train=0.0873, Val=0.0816\n",
      "Epoch 91: Train=0.0874, Val=0.0833\n",
      "Epoch 92: Train=0.0867, Val=0.0830\n",
      "Epoch 93: Train=0.0872, Val=0.0821\n",
      "Epoch 94: Train=0.0868, Val=0.0826\n",
      "Epoch 95: Train=0.0872, Val=0.0824\n",
      "Epoch 96: Train=0.0862, Val=0.0829\n",
      "Epoch 97: Train=0.0862, Val=0.0814\n",
      "Epoch 98: Train=0.0867, Val=0.0823\n",
      "Epoch 99: Train=0.0870, Val=0.0810\n",
      "Epoch 100: Train=0.0865, Val=0.0815\n",
      "Fold 3 | Macro F1: 0.7242\n",
      "\n",
      "========== Fold 4/5 ==========\n",
      "Epoch 1: Train=0.4995, Val=0.2034\n",
      "Epoch 2: Train=0.2080, Val=0.1774\n",
      "Epoch 3: Train=0.1806, Val=0.1578\n",
      "Epoch 4: Train=0.1660, Val=0.1403\n",
      "Epoch 5: Train=0.1556, Val=0.1314\n",
      "Epoch 6: Train=0.1427, Val=0.1211\n",
      "Epoch 7: Train=0.1343, Val=0.1235\n",
      "Epoch 8: Train=0.1287, Val=0.1123\n",
      "Epoch 9: Train=0.1260, Val=0.1106\n",
      "Epoch 10: Train=0.1228, Val=0.1151\n",
      "Epoch 11: Train=0.1195, Val=0.1035\n",
      "Epoch 12: Train=0.1200, Val=0.1085\n",
      "Epoch 13: Train=0.1164, Val=0.1143\n",
      "Epoch 14: Train=0.1162, Val=0.1004\n",
      "Epoch 15: Train=0.1114, Val=0.1031\n",
      "Epoch 16: Train=0.1095, Val=0.1027\n",
      "Epoch 17: Train=0.1086, Val=0.1000\n",
      "Epoch 18: Train=0.1092, Val=0.1054\n",
      "Epoch 19: Train=0.1090, Val=0.0986\n",
      "Epoch 20: Train=0.1055, Val=0.0968\n",
      "Epoch 21: Train=0.1071, Val=0.0976\n",
      "Epoch 22: Train=0.1034, Val=0.0968\n",
      "Epoch 23: Train=0.1016, Val=0.0952\n",
      "Epoch 24: Train=0.1010, Val=0.0954\n",
      "Epoch 25: Train=0.1010, Val=0.0946\n",
      "Epoch 26: Train=0.1002, Val=0.1158\n",
      "Epoch 27: Train=0.1012, Val=0.0918\n",
      "Epoch 28: Train=0.0982, Val=0.0922\n",
      "Epoch 29: Train=0.0981, Val=0.0957\n",
      "Epoch 30: Train=0.0987, Val=0.0918\n",
      "Epoch 31: Train=0.0969, Val=0.0913\n",
      "Epoch 32: Train=0.0961, Val=0.0893\n",
      "Epoch 33: Train=0.0954, Val=0.0914\n",
      "Epoch 34: Train=0.0952, Val=0.0899\n",
      "Epoch 35: Train=0.0953, Val=0.0907\n",
      "Epoch 36: Train=0.0947, Val=0.0901\n",
      "Epoch 37: Train=0.0945, Val=0.0919\n",
      "Epoch 38: Train=0.0935, Val=0.0912\n",
      "Epoch 39: Train=0.0937, Val=0.0901\n",
      "Epoch 40: Train=0.0930, Val=0.0906\n",
      "Epoch 41: Train=0.0936, Val=0.0888\n",
      "Epoch 42: Train=0.0932, Val=0.0895\n",
      "Epoch 43: Train=0.0923, Val=0.0901\n",
      "Epoch 44: Train=0.0919, Val=0.0905\n",
      "Epoch 45: Train=0.0919, Val=0.0884\n",
      "Epoch 46: Train=0.0912, Val=0.0910\n",
      "Epoch 47: Train=0.0916, Val=0.0883\n",
      "Epoch 48: Train=0.0914, Val=0.0881\n",
      "Epoch 49: Train=0.0910, Val=0.0879\n",
      "Epoch 50: Train=0.0907, Val=0.0879\n",
      "Epoch 51: Train=0.0904, Val=0.0881\n",
      "Epoch 52: Train=0.0910, Val=0.0896\n",
      "Epoch 53: Train=0.0908, Val=0.0894\n",
      "Epoch 54: Train=0.0905, Val=0.0867\n",
      "Epoch 55: Train=0.0895, Val=0.0876\n",
      "Epoch 56: Train=0.0900, Val=0.0890\n",
      "Epoch 57: Train=0.0898, Val=0.0864\n",
      "Epoch 58: Train=0.0893, Val=0.0874\n",
      "Epoch 59: Train=0.0894, Val=0.0896\n",
      "Epoch 60: Train=0.0887, Val=0.0872\n",
      "Epoch 61: Train=0.0895, Val=0.0863\n",
      "Epoch 62: Train=0.0890, Val=0.0862\n",
      "Epoch 63: Train=0.0888, Val=0.0871\n",
      "Epoch 64: Train=0.0887, Val=0.0848\n",
      "Epoch 65: Train=0.0891, Val=0.0864\n",
      "Epoch 66: Train=0.0883, Val=0.0863\n",
      "Epoch 67: Train=0.0883, Val=0.0892\n",
      "Epoch 68: Train=0.0880, Val=0.0861\n",
      "Epoch 69: Train=0.0883, Val=0.0865\n",
      "Epoch 70: Train=0.0876, Val=0.0857\n",
      "Epoch 71: Train=0.0891, Val=0.0876\n",
      "Epoch 72: Train=0.0889, Val=0.0858\n",
      "Epoch 73: Train=0.0873, Val=0.0851\n",
      "Epoch 74: Train=0.0878, Val=0.0860\n",
      "‚èπ Early stopping\n",
      "Fold 4 | Macro F1: 0.7369\n",
      "\n",
      "========== Fold 5/5 ==========\n",
      "Epoch 1: Train=0.5182, Val=0.2021\n",
      "Epoch 2: Train=0.2177, Val=0.1865\n",
      "Epoch 3: Train=0.1884, Val=0.1587\n",
      "Epoch 4: Train=0.1761, Val=0.1570\n",
      "Epoch 5: Train=0.1669, Val=0.1482\n",
      "Epoch 6: Train=0.1589, Val=0.1332\n",
      "Epoch 7: Train=0.1511, Val=0.1284\n",
      "Epoch 8: Train=0.1438, Val=0.1315\n",
      "Epoch 9: Train=0.1453, Val=0.1208\n",
      "Epoch 10: Train=0.1323, Val=0.1126\n",
      "Epoch 11: Train=0.1241, Val=0.1076\n",
      "Epoch 12: Train=0.1231, Val=0.1102\n",
      "Epoch 13: Train=0.1200, Val=0.1058\n",
      "Epoch 14: Train=0.1174, Val=0.1061\n",
      "Epoch 15: Train=0.1146, Val=0.1034\n",
      "Epoch 16: Train=0.1138, Val=0.1049\n",
      "Epoch 17: Train=0.1117, Val=0.1041\n",
      "Epoch 18: Train=0.1113, Val=0.1074\n",
      "Epoch 19: Train=0.1125, Val=0.0992\n",
      "Epoch 20: Train=0.1086, Val=0.0961\n",
      "Epoch 21: Train=0.1074, Val=0.1013\n",
      "Epoch 22: Train=0.1085, Val=0.1010\n",
      "Epoch 23: Train=0.1078, Val=0.0993\n",
      "Epoch 24: Train=0.1055, Val=0.0946\n",
      "Epoch 25: Train=0.1048, Val=0.0960\n",
      "Epoch 26: Train=0.1048, Val=0.0939\n",
      "Epoch 27: Train=0.1035, Val=0.0992\n",
      "Epoch 28: Train=0.1028, Val=0.0932\n",
      "Epoch 29: Train=0.1046, Val=0.0939\n",
      "Epoch 30: Train=0.1018, Val=0.0927\n",
      "Epoch 31: Train=0.1048, Val=0.0926\n",
      "Epoch 32: Train=0.1005, Val=0.0938\n",
      "Epoch 33: Train=0.0996, Val=0.0914\n",
      "Epoch 34: Train=0.0996, Val=0.0913\n",
      "Epoch 35: Train=0.0998, Val=0.0916\n",
      "Epoch 36: Train=0.1001, Val=0.0936\n",
      "Epoch 37: Train=0.0981, Val=0.0923\n",
      "Epoch 38: Train=0.0981, Val=0.1013\n",
      "Epoch 39: Train=0.0984, Val=0.0902\n",
      "Epoch 40: Train=0.0974, Val=0.0877\n",
      "Epoch 41: Train=0.0979, Val=0.0942\n",
      "Epoch 42: Train=0.0971, Val=0.0902\n",
      "Epoch 43: Train=0.0970, Val=0.0885\n",
      "Epoch 44: Train=0.0973, Val=0.0908\n",
      "Epoch 45: Train=0.0964, Val=0.0881\n",
      "Epoch 46: Train=0.0963, Val=0.0884\n",
      "Epoch 47: Train=0.0953, Val=0.0889\n",
      "Epoch 48: Train=0.0952, Val=0.0887\n",
      "Epoch 49: Train=0.0956, Val=0.0864\n",
      "Epoch 50: Train=0.0945, Val=0.0886\n",
      "Epoch 51: Train=0.0950, Val=0.0910\n",
      "Epoch 52: Train=0.0941, Val=0.0882\n",
      "Epoch 53: Train=0.0943, Val=0.0893\n",
      "Epoch 54: Train=0.0941, Val=0.0895\n",
      "Epoch 55: Train=0.0934, Val=0.0886\n",
      "Epoch 56: Train=0.0933, Val=0.0873\n",
      "Epoch 57: Train=0.0932, Val=0.0856\n",
      "Epoch 58: Train=0.0928, Val=0.0858\n",
      "Epoch 59: Train=0.0923, Val=0.0858\n",
      "Epoch 60: Train=0.0927, Val=0.0861\n",
      "Epoch 61: Train=0.0931, Val=0.0858\n",
      "Epoch 62: Train=0.0917, Val=0.0863\n",
      "Epoch 63: Train=0.0918, Val=0.0860\n",
      "Epoch 64: Train=0.0915, Val=0.0852\n",
      "Epoch 65: Train=0.0910, Val=0.0852\n",
      "Epoch 66: Train=0.0913, Val=0.0844\n",
      "Epoch 67: Train=0.0925, Val=0.0873\n",
      "Epoch 68: Train=0.0905, Val=0.0891\n",
      "Epoch 69: Train=0.0906, Val=0.0868\n",
      "Epoch 70: Train=0.0905, Val=0.0864\n",
      "Epoch 71: Train=0.0902, Val=0.0860\n",
      "Epoch 72: Train=0.0898, Val=0.0859\n",
      "Epoch 73: Train=0.0900, Val=0.0851\n",
      "Epoch 74: Train=0.0901, Val=0.0844\n",
      "Epoch 75: Train=0.0900, Val=0.0869\n",
      "Epoch 76: Train=0.0897, Val=0.0847\n",
      "Epoch 77: Train=0.0890, Val=0.0862\n",
      "Epoch 78: Train=0.0891, Val=0.0847\n",
      "Epoch 79: Train=0.0890, Val=0.0841\n",
      "Epoch 80: Train=0.0894, Val=0.0836\n",
      "Epoch 81: Train=0.0892, Val=0.0843\n",
      "Epoch 82: Train=0.0886, Val=0.0885\n",
      "Epoch 83: Train=0.0884, Val=0.0835\n",
      "Epoch 84: Train=0.0881, Val=0.0850\n",
      "Epoch 85: Train=0.0883, Val=0.0831\n",
      "Epoch 86: Train=0.0875, Val=0.0826\n",
      "Epoch 87: Train=0.0883, Val=0.0833\n",
      "Epoch 88: Train=0.0881, Val=0.0830\n",
      "Epoch 89: Train=0.0871, Val=0.0833\n",
      "Epoch 90: Train=0.0880, Val=0.0835\n",
      "Epoch 91: Train=0.0879, Val=0.0844\n",
      "Epoch 92: Train=0.0880, Val=0.0820\n",
      "Epoch 93: Train=0.0872, Val=0.0839\n",
      "Epoch 94: Train=0.0869, Val=0.0817\n",
      "Epoch 95: Train=0.0870, Val=0.0823\n",
      "Epoch 96: Train=0.0864, Val=0.0815\n",
      "Epoch 97: Train=0.0868, Val=0.0836\n",
      "Epoch 98: Train=0.0869, Val=0.0819\n",
      "Epoch 99: Train=0.0867, Val=0.0821\n",
      "Epoch 100: Train=0.0864, Val=0.0827\n",
      "Fold 5 | Macro F1: 0.7359\n",
      "\n",
      "üèÜ Best Model ‚Üí Fold 2 | Macro F1 = 0.7458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)  \n",
    "\n",
    "best_model, cnn_models, cnn_histories = kfold_training(\n",
    "    model_class=CNN1D,\n",
    "    model_kwargs={\"num_classes\": 12}, \n",
    "    X=X_scaled,\n",
    "    y=y_train,\n",
    "    k=5,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    patience=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-12T08:30:39.058301Z",
     "iopub.status.busy": "2026-01-12T08:30:39.057616Z",
     "iopub.status.idle": "2026-01-12T08:30:39.064745Z",
     "shell.execute_reply": "2026-01-12T08:30:39.064004Z",
     "shell.execute_reply.started": "2026-01-12T08:30:39.058280Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN1D(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): AdaptiveAvgPool1d(output_size=1)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=13, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(best_model\n",
    "     \n",
    "     )\n",
    "torch.save(\n",
    "    best_model.state_dict(),\n",
    "    \"/kaggle/working/cnn_1D_final_model_k_fold.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-12T09:55:54.441335Z",
     "iopub.status.busy": "2026-01-12T09:55:54.440620Z",
     "iopub.status.idle": "2026-01-12T09:55:54.451316Z",
     "shell.execute_reply": "2026-01-12T09:55:54.450604Z",
     "shell.execute_reply.started": "2026-01-12T09:55:54.441315Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model = CNN1D(\n",
    "    num_classes=12\n",
    ").to(device)\n",
    "cnn_model.load_state_dict(\n",
    "    torch.load(\n",
    "        r\"/kaggle/working/cnn_1D_final_model_k_fold.pt\",\n",
    "        map_location=device\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T10:12:25.035909Z",
     "iopub.status.busy": "2026-01-12T10:12:25.035225Z",
     "iopub.status.idle": "2026-01-12T10:12:25.273735Z",
     "shell.execute_reply": "2026-01-12T10:12:25.272913Z",
     "shell.execute_reply.started": "2026-01-12T10:12:25.035883Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9  4  4 ...  9 10  9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_test = predict_cnn(cnn_model, X_test)\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T10:12:43.663947Z",
     "iopub.status.busy": "2026-01-12T10:12:43.663480Z",
     "iopub.status.idle": "2026-01-12T10:12:43.668705Z",
     "shell.execute_reply": "2026-01-12T10:12:43.668093Z",
     "shell.execute_reply.started": "2026-01-12T10:12:43.663922Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  4,  4, ...,  9, 10,  9])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T10:48:17.763929Z",
     "iopub.status.busy": "2026-01-12T10:48:17.763367Z",
     "iopub.status.idle": "2026-01-12T10:48:18.085878Z",
     "shell.execute_reply": "2026-01-12T10:48:18.085304Z",
     "shell.execute_reply.started": "2026-01-12T10:48:17.763904Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Set Evaluation ===\n",
      "Accuracy      : 0.9600\n",
      "Macro F1      : 0.6759\n",
      "Weighted F1   : 0.9645\n",
      "Micro F1      : 0.9600\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       1.00      0.96      0.98     19566\n",
      "         DNS       0.37      0.29      0.33       734\n",
      "        LDAP       0.47      0.63      0.54       669\n",
      "       MSSQL       0.84      0.93      0.88      2947\n",
      "         NTP       1.00      0.99      0.99     24274\n",
      "     NetBIOS       0.52      0.78      0.62       248\n",
      "     Portmap       0.12      0.18      0.15       137\n",
      "        SNMP       0.50      0.54      0.52       543\n",
      "         Syn       1.00      0.99      0.99      9875\n",
      "        TFTP       1.00      0.99      1.00     19784\n",
      "         UDP       0.92      0.96      0.94      5702\n",
      "      UDPLag       0.92      0.74      0.82      1786\n",
      "     WebDDoS       0.01      0.90      0.02        10\n",
      "\n",
      "    accuracy                           0.96     86275\n",
      "   macro avg       0.67      0.76      0.68     86275\n",
      "weighted avg       0.97      0.96      0.96     86275\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9600231816864677,\n",
       " 'f1_macro': 0.6759355111878775,\n",
       " 'f1_weighted': 0.9645481435278768,\n",
       " 'f1_micro': 0.9600231816864677}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=== Test Set Evaluation ===\")\n",
    "evaluate_model(cnn_model, X_test, y_test, class_names=[\n",
    "    \"Benign\", \"DNS\", \"LDAP\", \"MSSQL\", \"NTP\", \"NetBIOS\",\n",
    "    \"Portmap\", \"SNMP\", \"Syn\", \"TFTP\", \"UDP\", \"UDPLag\", \"WebDDoS\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T10:45:45.861947Z",
     "iopub.status.busy": "2026-01-12T10:45:45.861349Z",
     "iopub.status.idle": "2026-01-12T10:45:45.895299Z",
     "shell.execute_reply": "2026-01-12T10:45:45.894769Z",
     "shell.execute_reply.started": "2026-01-12T10:45:45.861923Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV file created: predictions.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'prediction': y_pred_test})\n",
    "\n",
    "df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ CSV file created: predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9229119,
     "sourceId": 14448548,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9233160,
     "sourceId": 14455674,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9245393,
     "sourceId": 14474887,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 557123,
     "modelInstanceId": 544015,
     "sourceId": 715728,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
